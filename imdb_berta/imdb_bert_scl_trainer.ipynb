{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":3971,"databundleVersionId":32703,"sourceType":"competition"}],"dockerImageVersionId":30805,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from __future__ import print_function\n\nimport torch\nimport torch.nn as nn","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T13:41:43.751510Z","iopub.execute_input":"2024-12-04T13:41:43.752310Z","iopub.status.idle":"2024-12-04T13:41:43.756923Z","shell.execute_reply.started":"2024-12-04T13:41:43.752273Z","shell.execute_reply":"2024-12-04T13:41:43.755754Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"class SupConLoss(nn.Module):\n    \"\"\"Supervised Contrastive Learning: https://arxiv.org/pdf/2004.11362.pdf.\n    It also supports the unsupervised contrastive loss in SimCLR\"\"\"\n    def __init__(self, temperature=0.07, contrast_mode='all',\n                 base_temperature=0.07):\n        super(SupConLoss, self).__init__()\n        self.temperature = temperature\n        self.contrast_mode = contrast_mode\n        self.base_temperature = base_temperature\n\n    def forward(self, features, labels=None, mask=None):\n        \"\"\"Compute loss for model. If both `labels` and `mask` are None,\n        it degenerates to SimCLR unsupervised loss:\n        https://arxiv.org/pdf/2002.05709.pdf\n\n        Args:\n            features: hidden vector of shape [bsz, n_views, ...].\n            labels: ground truth of shape [bsz].\n            mask: contrastive mask of shape [bsz, bsz], mask_{i,j}=1 if sample j\n                has the same class as sample i. Can be asymmetric.\n        Returns:\n            A loss scalar.\n        \"\"\"\n        device = (torch.device('cuda')\n                  if features.is_cuda\n                  else torch.device('cpu'))\n\n        features = features.view(features.shape[0], features.shape[1], -1)\n\n        batch_size = features.shape[0]\n        if labels is not None and mask is not None:\n            raise ValueError('Cannot define both `labels` and `mask`')\n        elif labels is None and mask is None:\n            mask = torch.eye(batch_size, dtype=torch.float32).to(device)\n        elif labels is not None:\n            labels = labels.contiguous().view(-1, 1)\n            if labels.shape[0] != batch_size:\n                raise ValueError('Num of labels does not match num of features')\n            mask = torch.eq(labels, labels.T).float().to(device)\n        else:\n            mask = mask.float().to(device)\n\n        contrast_count = features.shape[1]\n        contrast_feature = torch.cat(torch.unbind(features, dim=1), dim=0)\n        if self.contrast_mode == 'one':\n            anchor_feature = features[:, 0]\n            anchor_count = 1\n        elif self.contrast_mode == 'all':\n            anchor_feature = contrast_feature\n            anchor_count = contrast_count\n        else:\n            raise ValueError('Unknown mode: {}'.format(self.contrast_mode))\n\n        # compute logits\n        anchor_dot_contrast = torch.div(\n            torch.matmul(anchor_feature, contrast_feature.T),\n            self.temperature)\n        # for numerical stability\n        logits_max, _ = torch.max(anchor_dot_contrast, dim=1, keepdim=True)\n        logits = anchor_dot_contrast - logits_max.detach()\n\n        # tile mask\n        mask = mask.repeat(anchor_count, contrast_count)\n        # mask-out self-contrast cases\n        logits_mask = torch.scatter(\n            torch.ones_like(mask),\n            1,\n            torch.arange(batch_size * anchor_count).view(-1, 1).to(device),\n            0\n        )\n        mask = mask * logits_mask\n\n        # compute log_prob\n        exp_logits = torch.exp(logits) * logits_mask\n        log_prob = logits - torch.log(exp_logits.sum(1, keepdim=True))\n\n        # compute mean of log-likelihood over positive\n        mean_log_prob_pos = (mask * log_prob).sum(1) / mask.sum(1)\n\n        # loss\n        loss = - (self.temperature / self.base_temperature) * mean_log_prob_pos\n        loss = loss.view(anchor_count, batch_size).mean()\n\n        return loss","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T13:41:46.721311Z","iopub.execute_input":"2024-12-04T13:41:46.721664Z","iopub.status.idle":"2024-12-04T13:41:46.734675Z","shell.execute_reply.started":"2024-12-04T13:41:46.721633Z","shell.execute_reply":"2024-12-04T13:41:46.733740Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"pip install evaluate","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T13:41:51.988567Z","iopub.execute_input":"2024-12-04T13:41:51.989409Z","iopub.status.idle":"2024-12-04T13:42:01.530578Z","shell.execute_reply.started":"2024-12-04T13:41:51.989376Z","shell.execute_reply":"2024-12-04T13:42:01.529507Z"}},"outputs":[{"name":"stdout","text":"Collecting evaluate\n  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\nRequirement already satisfied: datasets>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (3.1.0)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from evaluate) (1.26.4)\nRequirement already satisfied: dill in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.3.8)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.2.3)\nRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.32.3)\nRequirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from evaluate) (4.66.4)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from evaluate) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.70.16)\nRequirement already satisfied: fsspec>=2021.05.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.6.0)\nRequirement already satisfied: huggingface-hub>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.26.2)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from evaluate) (21.3)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (3.15.1)\nRequirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (17.0.0)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (3.9.5)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (6.0.2)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.7.0->evaluate) (4.12.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->evaluate) (3.1.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (2024.6.2)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2024.1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2024.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.2.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.5)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\nDownloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n\u001b[2K   \u001b[90m\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: evaluate\nSuccessfully installed evaluate-0.4.3\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"import os\nimport sys\nimport logging\nimport datasets\nimport evaluate\n\n\nimport torch.nn as nn\n\nimport pandas as pd\nimport numpy as np\n\nfrom transformers import BertTokenizerFast, DataCollatorWithPadding\nfrom transformers import Trainer, TrainingArguments\nfrom transformers import BertPreTrainedModel, BertModel\nfrom transformers.modeling_outputs import SequenceClassifierOutput\n\nfrom sklearn.model_selection import train_test_split","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T13:42:05.872936Z","iopub.execute_input":"2024-12-04T13:42:05.873722Z","iopub.status.idle":"2024-12-04T13:42:21.397301Z","shell.execute_reply.started":"2024-12-04T13:42:05.873668Z","shell.execute_reply":"2024-12-04T13:42:21.396572Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"! unzip /kaggle/input/word2vec-nlp-tutorial/labeledTrainData.tsv.zip\n! unzip /kaggle/input/word2vec-nlp-tutorial/testData.tsv.zip\n! unzip /kaggle/input/word2vec-nlp-tutorial/unlabeledTrainData.tsv.zip","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T13:42:30.790575Z","iopub.execute_input":"2024-12-04T13:42:30.791222Z","iopub.status.idle":"2024-12-04T13:42:35.240108Z","shell.execute_reply.started":"2024-12-04T13:42:30.791190Z","shell.execute_reply":"2024-12-04T13:42:35.238967Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  pid, fd = os.forkpty()\n","output_type":"stream"},{"name":"stdout","text":"Archive:  /kaggle/input/word2vec-nlp-tutorial/labeledTrainData.tsv.zip\n  inflating: labeledTrainData.tsv    \nArchive:  /kaggle/input/word2vec-nlp-tutorial/testData.tsv.zip\n  inflating: testData.tsv            \nArchive:  /kaggle/input/word2vec-nlp-tutorial/unlabeledTrainData.tsv.zip\n  inflating: unlabeledTrainData.tsv  \n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"train = pd.read_csv(\"/kaggle/working/labeledTrainData.tsv\", header=0, delimiter=\"\\t\", quoting=3)\ntest = pd.read_csv(\"/kaggle/working/testData.tsv\", header=0, delimiter=\"\\t\", quoting=3)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T13:42:38.294336Z","iopub.execute_input":"2024-12-04T13:42:38.294718Z","iopub.status.idle":"2024-12-04T13:42:39.057631Z","shell.execute_reply.started":"2024-12-04T13:42:38.294671Z","shell.execute_reply":"2024-12-04T13:42:39.056614Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"class BertScratch(BertPreTrainedModel):\n    def __init__(self, config):\n        super().__init__(config)\n        self.num_labels = config.num_labels\n        self.config = config\n        self.alpha = 0.2\n\n        self.bert = BertModel(config)\n        classifier_dropout = (\n            config.classifier_dropout if config.classifier_dropout is not None else config.hidden_dropout_prob\n        )\n        self.dropout = nn.Dropout(classifier_dropout)\n        self.classifier = nn.Linear(config.hidden_size, config.num_labels)\n\n        self.post_init()\n\n    def forward(self, input_ids=None, attention_mask=None, token_type_ids=None, labels=None):\n        outputs = self.bert(input_ids, attention_mask, token_type_ids)\n        pooled_output = outputs[1]\n        pooled_output = self.dropout(pooled_output)\n        logits = self.classifier(pooled_output)\n\n        loss = None\n        if labels is not None:\n            loss_fct = nn.CrossEntropyLoss()\n            ce_loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n\n            scl_fct = SupConLoss()\n            scl_loss = scl_fct(pooled_output, labels)\n\n            loss = ce_loss + self.alpha * scl_loss\n\n        return SequenceClassifierOutput(\n            loss=loss,\n            logits=logits,\n            hidden_states=outputs.hidden_states,\n            attentions=outputs.attentions\n        )\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T13:42:41.186196Z","iopub.execute_input":"2024-12-04T13:42:41.186549Z","iopub.status.idle":"2024-12-04T13:42:41.194375Z","shell.execute_reply.started":"2024-12-04T13:42:41.186517Z","shell.execute_reply":"2024-12-04T13:42:41.193532Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"program = os.path.basename(sys.argv[0])\nlogger = logging.getLogger(program)\n\nlogging.basicConfig(format='%(asctime)s: %(levelname)s: %(message)s')\nlogging.root.setLevel(level=logging.INFO)\nlogger.info(r\"running %s\" % ''.join(sys.argv))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T13:42:53.700145Z","iopub.execute_input":"2024-12-04T13:42:53.700972Z","iopub.status.idle":"2024-12-04T13:42:53.707113Z","shell.execute_reply.started":"2024-12-04T13:42:53.700934Z","shell.execute_reply":"2024-12-04T13:42:53.706233Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"train, val = train_test_split(train, test_size=.2)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T13:42:56.450805Z","iopub.execute_input":"2024-12-04T13:42:56.451481Z","iopub.status.idle":"2024-12-04T13:42:56.469392Z","shell.execute_reply.started":"2024-12-04T13:42:56.451447Z","shell.execute_reply":"2024-12-04T13:42:56.468600Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"train_dict = {'label': train[\"sentiment\"], 'text': train['review']}\nval_dict = {'label': val[\"sentiment\"], 'text': val['review']}\ntest_dict = {\"text\": test['review']}\n\ntrain_dataset = datasets.Dataset.from_dict(train_dict)\nval_dataset = datasets.Dataset.from_dict(val_dict)\ntest_dataset = datasets.Dataset.from_dict(test_dict)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T13:42:58.617903Z","iopub.execute_input":"2024-12-04T13:42:58.618501Z","iopub.status.idle":"2024-12-04T13:42:59.299355Z","shell.execute_reply.started":"2024-12-04T13:42:58.618466Z","shell.execute_reply":"2024-12-04T13:42:59.298659Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T13:43:01.785773Z","iopub.execute_input":"2024-12-04T13:43:01.786490Z","iopub.status.idle":"2024-12-04T13:43:05.085479Z","shell.execute_reply.started":"2024-12-04T13:43:01.786456Z","shell.execute_reply":"2024-12-04T13:43:05.084611Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f573f8eeb55d412d9c39c5cd978b3bbe"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8ae7ac35f53b4182bfec7355914296e7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"42956af15cb14bac9de82d3ec0c0257b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b7546a392cab4937b61617030a9c1233"}},"metadata":{}}],"execution_count":12},{"cell_type":"code","source":"def preprocess_function(examples):\n    return tokenizer(examples['text'], truncation=True)\n\n\ntokenized_train = train_dataset.map(preprocess_function, batched=True)\ntokenized_val = val_dataset.map(preprocess_function, batched=True)\ntokenized_test = test_dataset.map(preprocess_function, batched=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T13:43:07.266511Z","iopub.execute_input":"2024-12-04T13:43:07.266887Z","iopub.status.idle":"2024-12-04T13:43:31.877243Z","shell.execute_reply.started":"2024-12-04T13:43:07.266853Z","shell.execute_reply":"2024-12-04T13:43:31.876514Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/20000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e2668787aefd4bf4b7784dd6cf6f35aa"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/5000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c1256dcf4803473ebb39685ff77ef637"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/25000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3ef4cd29c4534c7385cc1797e5f35c3e"}},"metadata":{}}],"execution_count":13},{"cell_type":"code","source":"data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n\nmodel = BertScratch.from_pretrained('bert-base-uncased')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T13:43:39.283659Z","iopub.execute_input":"2024-12-04T13:43:39.284510Z","iopub.status.idle":"2024-12-04T13:43:42.226272Z","shell.execute_reply.started":"2024-12-04T13:43:39.284474Z","shell.execute_reply":"2024-12-04T13:43:42.225619Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7e0aa32fbb0c4a7e908373528e4024f3"}},"metadata":{}},{"name":"stderr","text":"Some weights of BertScratch were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"metric = evaluate.load(\"accuracy\")\n\n\ndef compute_metrics(eval_pred):\n    logits, labels = eval_pred\n    predictions = np.argmax(logits, axis=-1)\n    return metric.compute(predictions=predictions, references=labels)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T13:43:45.971032Z","iopub.execute_input":"2024-12-04T13:43:45.971373Z","iopub.status.idle":"2024-12-04T13:43:47.697117Z","shell.execute_reply.started":"2024-12-04T13:43:45.971343Z","shell.execute_reply":"2024-12-04T13:43:47.696262Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/4.20k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e59fc66e95b84c7a935b61dc29fa3508"}},"metadata":{}}],"execution_count":15},{"cell_type":"code","source":"training_args = TrainingArguments(\n    output_dir='./scl',  # output directory\n    num_train_epochs=3,  # total number of training epochs\n    per_device_train_batch_size=8,  # batch size per device during training\n    per_device_eval_batch_size=16,  # batch size for evaluation\n    warmup_steps=500,  # number of warmup steps for learning rate scheduler\n    weight_decay=0.01,  # strength of weight decay\n    logging_dir='./logs',  # directory for storing logs\n    logging_steps=100,\n    save_strategy=\"no\",\n    evaluation_strategy=\"epoch\"\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T13:43:50.676704Z","iopub.execute_input":"2024-12-04T13:43:50.677048Z","iopub.status.idle":"2024-12-04T13:43:50.793519Z","shell.execute_reply.started":"2024-12-04T13:43:50.677019Z","shell.execute_reply":"2024-12-04T13:43:50.792630Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of  Transformers. Use `eval_strategy` instead\n  warnings.warn(\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"trainer = Trainer(\n    model=model,  # the instantiated  Transformers model to be trained\n    args=training_args,  # training arguments, defined above\n    train_dataset=tokenized_train,  # training dataset\n    eval_dataset=tokenized_val,  # evaluation dataset\n    tokenizer=tokenizer,\n    data_collator=data_collator,\n    compute_metrics=compute_metrics,\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T13:43:53.513187Z","iopub.execute_input":"2024-12-04T13:43:53.513536Z","iopub.status.idle":"2024-12-04T13:43:55.138712Z","shell.execute_reply.started":"2024-12-04T13:43:53.513503Z","shell.execute_reply":"2024-12-04T13:43:55.137810Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_23/2179846710.py:1: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n  trainer = Trainer(\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"trainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T13:43:56.973509Z","iopub.execute_input":"2024-12-04T13:43:56.973870Z","iopub.status.idle":"2024-12-04T14:44:58.638327Z","shell.execute_reply.started":"2024-12-04T13:43:56.973837Z","shell.execute_reply":"2024-12-04T14:44:58.637609Z"}},"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  路路路路路路路路\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.18.7"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20241204_134428-v6g1109t</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/hideonbush6060-666/huggingface/runs/v6g1109t' target=\"_blank\">./scl</a></strong> to <a href='https://wandb.ai/hideonbush6060-666/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/hideonbush6060-666/huggingface' target=\"_blank\">https://wandb.ai/hideonbush6060-666/huggingface</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/hideonbush6060-666/huggingface/runs/v6g1109t' target=\"_blank\">https://wandb.ai/hideonbush6060-666/huggingface/runs/v6g1109t</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='7500' max='7500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [7500/7500 1:00:26, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>1.940300</td>\n      <td>2.080377</td>\n      <td>0.926200</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>1.860300</td>\n      <td>2.080033</td>\n      <td>0.932400</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>1.764800</td>\n      <td>2.169894</td>\n      <td>0.932000</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=7500, training_loss=1.8973277079264323, metrics={'train_runtime': 3661.3311, 'train_samples_per_second': 16.387, 'train_steps_per_second': 2.048, 'total_flos': 1.49337723912096e+16, 'train_loss': 1.8973277079264323, 'epoch': 3.0})"},"metadata":{}}],"execution_count":18},{"cell_type":"code","source":"prediction_outputs = trainer.predict(tokenized_test)\ntest_pred = np.argmax(prediction_outputs[0], axis=-1).flatten()\nprint(test_pred)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T14:48:28.199580Z","iopub.execute_input":"2024-12-04T14:48:28.200037Z","iopub.status.idle":"2024-12-04T14:55:10.094114Z","shell.execute_reply.started":"2024-12-04T14:48:28.199998Z","shell.execute_reply":"2024-12-04T14:55:10.093240Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"[1 0 1 ... 0 1 1]\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"result_output = pd.DataFrame(data={\"id\": test[\"id\"], \"sentiment\": test_pred})\nresult_output.to_csv(\"bert_scl.csv\", index=False, quoting=3)\nlogging.info('result saved!')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T14:57:44.270813Z","iopub.execute_input":"2024-12-04T14:57:44.271187Z","iopub.status.idle":"2024-12-04T14:57:44.300447Z","shell.execute_reply.started":"2024-12-04T14:57:44.271155Z","shell.execute_reply":"2024-12-04T14:57:44.299801Z"}},"outputs":[],"execution_count":20}]}