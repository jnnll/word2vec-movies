{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":3971,"databundleVersionId":32703,"sourceType":"competition"}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pip install evaluate","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-03T08:35:42.164949Z","iopub.execute_input":"2024-12-03T08:35:42.165809Z","iopub.status.idle":"2024-12-03T08:35:50.314395Z","shell.execute_reply.started":"2024-12-03T08:35:42.165768Z","shell.execute_reply":"2024-12-03T08:35:50.313158Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  pid, fd = os.forkpty()\n","output_type":"stream"},{"name":"stdout","text":"Requirement already satisfied: evaluate in /opt/conda/lib/python3.10/site-packages (0.4.3)\nRequirement already satisfied: datasets>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (3.0.1)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from evaluate) (1.26.4)\nRequirement already satisfied: dill in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.3.8)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.2.2)\nRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.32.3)\nRequirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from evaluate) (4.66.4)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from evaluate) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.70.16)\nRequirement already satisfied: fsspec>=2021.05.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.6.1)\nRequirement already satisfied: huggingface-hub>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.25.1)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from evaluate) (21.3)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (3.15.1)\nRequirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (16.1.0)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (3.9.5)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (6.0.2)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.7.0->evaluate) (4.12.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->evaluate) (3.1.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (2024.8.30)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2024.1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2024.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.2.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.5)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"pip install peft==0.12.0","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-03T08:36:06.534179Z","iopub.execute_input":"2024-12-03T08:36:06.534541Z","iopub.status.idle":"2024-12-03T08:36:14.674773Z","shell.execute_reply.started":"2024-12-03T08:36:06.534507Z","shell.execute_reply":"2024-12-03T08:36:14.673737Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: peft==0.12.0 in /opt/conda/lib/python3.10/site-packages (0.12.0)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from peft==0.12.0) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from peft==0.12.0) (21.3)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from peft==0.12.0) (5.9.3)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from peft==0.12.0) (6.0.2)\nRequirement already satisfied: torch>=1.13.0 in /opt/conda/lib/python3.10/site-packages (from peft==0.12.0) (2.4.0)\nRequirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (from peft==0.12.0) (4.45.1)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from peft==0.12.0) (4.66.4)\nRequirement already satisfied: accelerate>=0.21.0 in /opt/conda/lib/python3.10/site-packages (from peft==0.12.0) (0.34.2)\nRequirement already satisfied: safetensors in /opt/conda/lib/python3.10/site-packages (from peft==0.12.0) (0.4.5)\nRequirement already satisfied: huggingface-hub>=0.17.0 in /opt/conda/lib/python3.10/site-packages (from peft==0.12.0) (0.25.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft==0.12.0) (3.15.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft==0.12.0) (2024.6.1)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft==0.12.0) (2.32.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft==0.12.0) (4.12.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->peft==0.12.0) (3.1.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.12.0) (1.13.3)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.12.0) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.12.0) (3.1.4)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers->peft==0.12.0) (2024.5.15)\nRequirement already satisfied: tokenizers<0.21,>=0.20 in /opt/conda/lib/python3.10/site-packages (from transformers->peft==0.12.0) (0.20.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.13.0->peft==0.12.0) (2.1.5)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft==0.12.0) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft==0.12.0) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft==0.12.0) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft==0.12.0) (2024.8.30)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.13.0->peft==0.12.0) (1.3.0)\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":16},{"cell_type":"markdown","source":"导入所需的库","metadata":{}},{"cell_type":"code","source":"# 导入所需的python库\nimport os\nimport sys\nimport logging\nimport datasets\nimport evaluate\n\n# 导入数据处理库\nimport pandas as pd\nimport numpy as np\n\n# 从transformers库导入模型和分词器\nfrom transformers import AutoModelForSequenceClassification, DebertaV2Tokenizer, DataCollatorWithPadding\n\n# 导入训练器和训练参数\nfrom transformers import Trainer, TrainingArguments\n\n# 从peft库导入配置和模型获取函数\nfrom peft import PromptTuningConfig, get_peft_model, TaskType\n\n# 从sklearn库导入数据集分割函数\nfrom sklearn.model_selection import train_test_split","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-03T08:36:24.060256Z","iopub.execute_input":"2024-12-03T08:36:24.061011Z","iopub.status.idle":"2024-12-03T08:36:24.067930Z","shell.execute_reply.started":"2024-12-03T08:36:24.060958Z","shell.execute_reply":"2024-12-03T08:36:24.066939Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"! unzip /kaggle/input/word2vec-nlp-tutorial/labeledTrainData.tsv.zip\n! unzip /kaggle/input/word2vec-nlp-tutorial/testData.tsv.zip\n! unzip /kaggle/input/word2vec-nlp-tutorial/unlabeledTrainData.tsv.zip","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-03T08:36:36.715807Z","iopub.execute_input":"2024-12-03T08:36:36.716132Z","iopub.status.idle":"2024-12-03T08:36:56.224430Z","shell.execute_reply.started":"2024-12-03T08:36:36.716105Z","shell.execute_reply":"2024-12-03T08:36:56.223341Z"}},"outputs":[{"name":"stdout","text":"Archive:  /kaggle/input/word2vec-nlp-tutorial/labeledTrainData.tsv.zip\nreplace labeledTrainData.tsv? [y]es, [n]o, [A]ll, [N]one, [r]ename: ^C\nArchive:  /kaggle/input/word2vec-nlp-tutorial/testData.tsv.zip\nreplace testData.tsv? [y]es, [n]o, [A]ll, [N]one, [r]ename: ^C\nArchive:  /kaggle/input/word2vec-nlp-tutorial/unlabeledTrainData.tsv.zip\nreplace unlabeledTrainData.tsv? [y]es, [n]o, [A]ll, [N]one, [r]ename: ^C\n","output_type":"stream"}],"execution_count":18},{"cell_type":"markdown","source":"读取训练和测试数据集","metadata":{}},{"cell_type":"code","source":"train = pd.read_csv(\"/kaggle/working/labeledTrainData.tsv\", header=0, delimiter=\"\\t\", quoting=3)\ntest = pd.read_csv(\"/kaggle/working/testData.tsv\", header=0, delimiter=\"\\t\", quoting=3)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-03T08:37:03.619229Z","iopub.execute_input":"2024-12-03T08:37:03.619599Z","iopub.status.idle":"2024-12-03T08:37:04.370063Z","shell.execute_reply.started":"2024-12-03T08:37:03.619566Z","shell.execute_reply":"2024-12-03T08:37:04.369269Z"}},"outputs":[],"execution_count":19},{"cell_type":"markdown","source":"设置日志记录的基本配置，并记录程序运行的开始","metadata":{}},{"cell_type":"code","source":"program = os.path.basename(sys.argv[0])\nlogger = logging.getLogger(program)\n\nlogging.basicConfig(format='%(asctime)s: %(levelname)s: %(message)s')\nlogging.root.setLevel(level=logging.INFO)\nlogger.info(r\"running %s\" % ''.join(sys.argv))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-03T08:37:12.039145Z","iopub.execute_input":"2024-12-03T08:37:12.039472Z","iopub.status.idle":"2024-12-03T08:37:12.045935Z","shell.execute_reply.started":"2024-12-03T08:37:12.039445Z","shell.execute_reply":"2024-12-03T08:37:12.045059Z"}},"outputs":[],"execution_count":20},{"cell_type":"markdown","source":"将训练数据集分割为训练集和验证集，其中20%作为验证集","metadata":{}},{"cell_type":"code","source":"train, val = train_test_split(train, test_size=.2)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-03T08:37:33.645378Z","iopub.execute_input":"2024-12-03T08:37:33.645750Z","iopub.status.idle":"2024-12-03T08:37:33.656075Z","shell.execute_reply.started":"2024-12-03T08:37:33.645698Z","shell.execute_reply":"2024-12-03T08:37:33.655142Z"}},"outputs":[],"execution_count":21},{"cell_type":"markdown","source":"创建字典，将标签和文本分别存储，以适配模型的输入格式。\n并将字典转换为datasets库的数据集对象。","metadata":{}},{"cell_type":"code","source":"    train_dict = {'label': train[\"sentiment\"], 'text': train['review']}\n    val_dict = {'label': val[\"sentiment\"], 'text': val['review']}\n    test_dict = {\"text\": test['review']}\n\n    train_dataset = datasets.Dataset.from_dict(train_dict)\n    val_dataset = datasets.Dataset.from_dict(val_dict)\n    test_dataset = datasets.Dataset.from_dict(test_dict)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-03T08:37:41.795246Z","iopub.execute_input":"2024-12-03T08:37:41.795596Z","iopub.status.idle":"2024-12-03T08:37:42.564866Z","shell.execute_reply.started":"2024-12-03T08:37:41.795564Z","shell.execute_reply":"2024-12-03T08:37:42.564132Z"}},"outputs":[],"execution_count":22},{"cell_type":"markdown","source":"指定了预训练模型的ID，并从指定的模型ID加载分词器。","metadata":{}},{"cell_type":"code","source":"    model_id = \"microsoft/deberta-v3-large\"\n\n    tokenizer = DebertaV2Tokenizer.from_pretrained(model_id)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-03T08:37:52.928518Z","iopub.execute_input":"2024-12-03T08:37:52.928905Z","iopub.status.idle":"2024-12-03T08:37:53.666048Z","shell.execute_reply.started":"2024-12-03T08:37:52.928871Z","shell.execute_reply":"2024-12-03T08:37:53.665103Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\n","output_type":"stream"}],"execution_count":23},{"cell_type":"markdown","source":"定义预处理函数，对文本进行分词处理，设置截断和填充。","metadata":{}},{"cell_type":"code","source":"def preprocess_function(examples):\n        return tokenizer(examples['text'], truncation=True,padding='max_length', max_length=510)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-03T08:38:02.797826Z","iopub.execute_input":"2024-12-03T08:38:02.798140Z","iopub.status.idle":"2024-12-03T08:38:02.802479Z","shell.execute_reply.started":"2024-12-03T08:38:02.798112Z","shell.execute_reply":"2024-12-03T08:38:02.801487Z"}},"outputs":[],"execution_count":24},{"cell_type":"markdown","source":"对训练集、验证集和测试集应用预处理函数对文本进行分词处理，设置截断和填充。","metadata":{}},{"cell_type":"code","source":"tokenized_train = train_dataset.map(preprocess_function, batched=True)\ntokenized_val = val_dataset.map(preprocess_function, batched=True)\ntokenized_test = test_dataset.map(preprocess_function, batched=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-03T08:38:11.733094Z","iopub.execute_input":"2024-12-03T08:38:11.733708Z","iopub.status.idle":"2024-12-03T08:39:21.537585Z","shell.execute_reply.started":"2024-12-03T08:38:11.733669Z","shell.execute_reply":"2024-12-03T08:39:21.536705Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/20000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8809643713384fa68d297bf33c256bab"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/5000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"333745386f3c429da3a8d26a69076cb0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/25000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6691269918f944b7bf8aec252d740c73"}},"metadata":{}}],"execution_count":25},{"cell_type":"markdown","source":"创建一个数据填充器，用于在训练时自动填充批次。并从指定的模型ID加载预训练模型。","metadata":{}},{"cell_type":"code","source":"data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n\nmodel = AutoModelForSequenceClassification.from_pretrained(model_id)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-03T08:39:26.264054Z","iopub.execute_input":"2024-12-03T08:39:26.265018Z","iopub.status.idle":"2024-12-03T08:39:27.822976Z","shell.execute_reply.started":"2024-12-03T08:39:26.264984Z","shell.execute_reply":"2024-12-03T08:39:27.822162Z"}},"outputs":[{"name":"stderr","text":"Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-large and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}],"execution_count":26},{"cell_type":"markdown","source":"定义LoRA配置并准备模型。","metadata":{}},{"cell_type":"code","source":"# Define LoRA Config\npeft_config = PromptTuningConfig(\n    num_virtual_tokens=10,\n    task_type=TaskType.SEQ_CLS\n)\n\n# prepare int-8 model for training\n#model = prepare_model_for_kbit_training(model)\n# add LoRA adaptor\nmodel = get_peft_model(model, peft_config)\nmodel.print_trainable_parameters()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-03T08:39:35.888516Z","iopub.execute_input":"2024-12-03T08:39:35.888962Z","iopub.status.idle":"2024-12-03T08:39:35.908884Z","shell.execute_reply.started":"2024-12-03T08:39:35.888930Z","shell.execute_reply":"2024-12-03T08:39:35.908054Z"}},"outputs":[{"name":"stdout","text":"trainable params: 12,290 || all params: 435,076,100 || trainable%: 0.0028\n","output_type":"stream"}],"execution_count":27},{"cell_type":"markdown","source":"加载准确率作为评估指标，并定义计算评估指标的函数，计算模型预测的准确率。","metadata":{}},{"cell_type":"code","source":"metric = evaluate.load(\"accuracy\")\ndef compute_metrics(eval_pred):\n    logits, labels = eval_pred\n    predictions = np.argmax(logits, axis=-1)\n    return metric.compute(predictions=predictions, references=labels)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-03T08:39:44.108471Z","iopub.execute_input":"2024-12-03T08:39:44.108854Z","iopub.status.idle":"2024-12-03T08:39:45.549706Z","shell.execute_reply.started":"2024-12-03T08:39:44.108824Z","shell.execute_reply":"2024-12-03T08:39:45.549114Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/4.20k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ef785d0d741247bb8129dca2b1340b3f"}},"metadata":{}}],"execution_count":28},{"cell_type":"markdown","source":"定义了训练参数，包括输出目录、训练轮数、批次大小等。","metadata":{}},{"cell_type":"code","source":"training_args = TrainingArguments(\n    output_dir='./checkpoint',  # output directory\n    num_train_epochs=3,  # total number of training epochs\n    per_device_train_batch_size=2,  # batch size per device during training\n    per_device_eval_batch_size=4,  # batch size for evaluation\n    warmup_steps=500,  # number of warmup steps for learning rate scheduler\n    weight_decay=0.01,  # strength of weight decay\n    logging_dir='./logs',  # directory for storing logs\n    logging_steps=100,\n    save_strategy=\"no\",\n    evaluation_strategy=\"epoch\"\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-03T08:39:57.717949Z","iopub.execute_input":"2024-12-03T08:39:57.718817Z","iopub.status.idle":"2024-12-03T08:39:57.799209Z","shell.execute_reply.started":"2024-12-03T08:39:57.718782Z","shell.execute_reply":"2024-12-03T08:39:57.798337Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1545: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n  warnings.warn(\n","output_type":"stream"}],"execution_count":29},{"cell_type":"markdown","source":"创建一个训练器对象，传入模型、训练参数、数据集等。","metadata":{}},{"cell_type":"code","source":"trainer = Trainer(\n    model=model,  # the instantiated 🤗 Transformers model to be trained\n    args=training_args,  # training arguments, defined above\n    train_dataset=tokenized_train,  # training dataset\n    eval_dataset=tokenized_val,  # evaluation dataset\n    tokenizer=tokenizer,\n    data_collator=data_collator,\n    compute_metrics=compute_metrics,\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-03T08:40:04.250674Z","iopub.execute_input":"2024-12-03T08:40:04.251053Z","iopub.status.idle":"2024-12-03T08:40:05.560645Z","shell.execute_reply.started":"2024-12-03T08:40:04.251023Z","shell.execute_reply":"2024-12-03T08:40:05.559786Z"}},"outputs":[],"execution_count":30},{"cell_type":"markdown","source":"开始训练。","metadata":{}},{"cell_type":"code","source":"trainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-03T08:40:13.665790Z","iopub.execute_input":"2024-12-03T08:40:13.666148Z"}},"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  ········\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01111558231111, max=1.0)))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b7bcbac53f2545e7b6a4740079a3de6e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.18.3"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20241203_084040-owny3epa</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/jiunianllin-/huggingface/runs/owny3epa' target=\"_blank\">./checkpoint</a></strong> to <a href='https://wandb.ai/jiunianllin-/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/jiunianllin-/huggingface' target=\"_blank\">https://wandb.ai/jiunianllin-/huggingface</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/jiunianllin-/huggingface/runs/owny3epa' target=\"_blank\">https://wandb.ai/jiunianllin-/huggingface/runs/owny3epa</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='8987' max='30000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [ 8987/30000 1:04:32 < 2:30:56, 2.32 it/s, Epoch 0.90/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table><p>"},"metadata":{}}],"execution_count":null},{"cell_type":"markdown","source":"对测试集进行预测，并打印预测结果。","metadata":{}},{"cell_type":"code","source":"prediction_outputs = trainer.predict(tokenized_test)\ntest_pred = np.argmax(prediction_outputs[0], axis=-1).flatten()\nprint(test_pred)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"将预测结果保存为CSV文件，并记录日志表示结果已保存。","metadata":{}},{"cell_type":"code","source":"result_output = pd.DataFrame(data={\"id\": test[\"id\"], \"sentiment\": test_pred})\nresult_output.to_csv(\"/kaggle/working/deberta_prompt.csv\", index=False, quoting=3)\n# result_output.to_csv(\"/kaggle/working/submission.csv\", index=False, quoting=3)\nlogging.info('result saved!')","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}