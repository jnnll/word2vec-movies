{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":3971,"databundleVersionId":32703,"sourceType":"competition"}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pip install evaluate","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-01T11:05:34.130425Z","iopub.execute_input":"2024-12-01T11:05:34.130774Z","iopub.status.idle":"2024-12-01T11:05:43.500471Z","shell.execute_reply.started":"2024-12-01T11:05:34.130744Z","shell.execute_reply":"2024-12-01T11:05:43.499222Z"}},"outputs":[{"name":"stdout","text":"Collecting evaluate\n  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\nRequirement already satisfied: datasets>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (3.0.1)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from evaluate) (1.26.4)\nRequirement already satisfied: dill in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.3.8)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.2.2)\nRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.32.3)\nRequirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from evaluate) (4.66.4)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from evaluate) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.70.16)\nRequirement already satisfied: fsspec>=2021.05.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.6.1)\nRequirement already satisfied: huggingface-hub>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.25.1)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from evaluate) (21.3)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (3.15.1)\nRequirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (16.1.0)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (3.9.5)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (6.0.2)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.7.0->evaluate) (4.12.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->evaluate) (3.1.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (2024.8.30)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2024.1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2024.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.2.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.5)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\nDownloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: evaluate\nSuccessfully installed evaluate-0.4.3\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"pip install peft","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-01T11:05:47.686247Z","iopub.execute_input":"2024-12-01T11:05:47.686595Z","iopub.status.idle":"2024-12-01T11:05:56.229033Z","shell.execute_reply.started":"2024-12-01T11:05:47.686565Z","shell.execute_reply":"2024-12-01T11:05:56.227929Z"}},"outputs":[{"name":"stdout","text":"Collecting peft\n  Downloading peft-0.13.2-py3-none-any.whl.metadata (13 kB)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from peft) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from peft) (21.3)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from peft) (5.9.3)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from peft) (6.0.2)\nRequirement already satisfied: torch>=1.13.0 in /opt/conda/lib/python3.10/site-packages (from peft) (2.4.0)\nRequirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (from peft) (4.45.1)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from peft) (4.66.4)\nRequirement already satisfied: accelerate>=0.21.0 in /opt/conda/lib/python3.10/site-packages (from peft) (0.34.2)\nRequirement already satisfied: safetensors in /opt/conda/lib/python3.10/site-packages (from peft) (0.4.5)\nRequirement already satisfied: huggingface-hub>=0.17.0 in /opt/conda/lib/python3.10/site-packages (from peft) (0.25.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (3.15.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (2024.6.1)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (2.32.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (4.12.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->peft) (3.1.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (1.13.3)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.1.4)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers->peft) (2024.5.15)\nRequirement already satisfied: tokenizers<0.21,>=0.20 in /opt/conda/lib/python3.10/site-packages (from transformers->peft) (0.20.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.13.0->peft) (2.1.5)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (2024.8.30)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.13.0->peft) (1.3.0)\nDownloading peft-0.13.2-py3-none-any.whl (320 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m320.7/320.7 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: peft\nSuccessfully installed peft-0.13.2\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":3},{"cell_type":"markdown","source":"导入python库","metadata":{}},{"cell_type":"code","source":"import os\nimport sys\nimport logging\nimport datasets\nimport evaluate\n\nimport pandas as pd\nimport numpy as np\n\nfrom transformers import DebertaV2ForSequenceClassification, DebertaV2Tokenizer, DataCollatorWithPadding\nfrom transformers import Trainer, TrainingArguments\nfrom peft import LoraConfig, get_peft_model, TaskType\nfrom sklearn.model_selection import train_test_split","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-01T11:06:00.791108Z","iopub.execute_input":"2024-12-01T11:06:00.791833Z","iopub.status.idle":"2024-12-01T11:06:19.226348Z","shell.execute_reply.started":"2024-12-01T11:06:00.791799Z","shell.execute_reply":"2024-12-01T11:06:19.225665Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"! unzip /kaggle/input/word2vec-nlp-tutorial/labeledTrainData.tsv.zip\n! unzip /kaggle/input/word2vec-nlp-tutorial/testData.tsv.zip\n! unzip /kaggle/input/word2vec-nlp-tutorial/unlabeledTrainData.tsv.zip","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-01T11:06:23.984451Z","iopub.execute_input":"2024-12-01T11:06:23.985583Z","iopub.status.idle":"2024-12-01T11:06:28.417360Z","shell.execute_reply.started":"2024-12-01T11:06:23.985548Z","shell.execute_reply":"2024-12-01T11:06:28.416276Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  pid, fd = os.forkpty()\n","output_type":"stream"},{"name":"stdout","text":"Archive:  /kaggle/input/word2vec-nlp-tutorial/labeledTrainData.tsv.zip\n  inflating: labeledTrainData.tsv    \nArchive:  /kaggle/input/word2vec-nlp-tutorial/testData.tsv.zip\n  inflating: testData.tsv            \nArchive:  /kaggle/input/word2vec-nlp-tutorial/unlabeledTrainData.tsv.zip\n  inflating: unlabeledTrainData.tsv  \n","output_type":"stream"}],"execution_count":5},{"cell_type":"markdown","source":"读取训练和测试数据集","metadata":{}},{"cell_type":"code","source":"train = pd.read_csv(\"/kaggle/working/labeledTrainData.tsv\", header=0, delimiter=\"\\t\", quoting=3)\ntest = pd.read_csv(\"/kaggle/working/testData.tsv\", header=0, delimiter=\"\\t\", quoting=3)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-01T11:06:30.738793Z","iopub.execute_input":"2024-12-01T11:06:30.739663Z","iopub.status.idle":"2024-12-01T11:06:31.480749Z","shell.execute_reply.started":"2024-12-01T11:06:30.739625Z","shell.execute_reply":"2024-12-01T11:06:31.480046Z"}},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":"设置日志记录的基本配置，并记录程序运行的开始","metadata":{}},{"cell_type":"code","source":"program = os.path.basename(sys.argv[0])\nlogger = logging.getLogger(program)\n\nlogging.basicConfig(format='%(asctime)s: %(levelname)s: %(message)s')\nlogging.root.setLevel(level=logging.INFO)\nlogger.info(r\"running %s\" % ''.join(sys.argv))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-01T11:06:33.400896Z","iopub.execute_input":"2024-12-01T11:06:33.401753Z","iopub.status.idle":"2024-12-01T11:06:33.407725Z","shell.execute_reply.started":"2024-12-01T11:06:33.401717Z","shell.execute_reply":"2024-12-01T11:06:33.406903Z"}},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":"将训练数据集分割为训练集和验证集，其中20%作为验证集","metadata":{}},{"cell_type":"code","source":"train, val = train_test_split(train, test_size=.2)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-01T11:06:35.714483Z","iopub.execute_input":"2024-12-01T11:06:35.715195Z","iopub.status.idle":"2024-12-01T11:06:35.731327Z","shell.execute_reply.started":"2024-12-01T11:06:35.715161Z","shell.execute_reply":"2024-12-01T11:06:35.730480Z"}},"outputs":[],"execution_count":8},{"cell_type":"markdown","source":"创建字典，将标签和文本分别存储，以适配模型的输入格式，并将字典转换为datasets库的数据集对象","metadata":{}},{"cell_type":"code","source":"train_dict = {'label': train[\"sentiment\"], 'text': train['review']}\nval_dict = {'label': val[\"sentiment\"], 'text': val['review']}\ntest_dict = {\"text\": test['review']}\n\ntrain_dataset = datasets.Dataset.from_dict(train_dict)\nval_dataset = datasets.Dataset.from_dict(val_dict)\ntest_dataset = datasets.Dataset.from_dict(test_dict)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-01T11:06:37.241078Z","iopub.execute_input":"2024-12-01T11:06:37.241515Z","iopub.status.idle":"2024-12-01T11:06:37.900070Z","shell.execute_reply.started":"2024-12-01T11:06:37.241478Z","shell.execute_reply":"2024-12-01T11:06:37.899112Z"}},"outputs":[],"execution_count":9},{"cell_type":"markdown","source":"指定了预训练模型的ID并从指定的模型ID加载分词器。","metadata":{}},{"cell_type":"code","source":"model_id = \"microsoft/deberta-v3-large\"\n\ntokenizer = DebertaV2Tokenizer.from_pretrained(model_id)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-01T11:06:39.944007Z","iopub.execute_input":"2024-12-01T11:06:39.944802Z","iopub.status.idle":"2024-12-01T11:06:41.447316Z","shell.execute_reply.started":"2024-12-01T11:06:39.944769Z","shell.execute_reply":"2024-12-01T11:06:41.446387Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/52.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ebe0297bfb064e42bac15fa49146d7f1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"spm.model:   0%|          | 0.00/2.46M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"62ffc72719ba49f49fb1b99f9647d3c9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/580 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fb162a62d5f143faaddcb1964ae26449"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\n","output_type":"stream"}],"execution_count":10},{"cell_type":"markdown","source":"定义预处理函数，对文本进行分词处理，设置截断和填充，并对训练集、验证集和测试集应用预处理函数。","metadata":{}},{"cell_type":"code","source":"def preprocess_function(examples):\n    return tokenizer(examples['text'], truncation=True,padding='max_length', max_length=510)\n\ntokenized_train = train_dataset.map(preprocess_function, batched=True)\ntokenized_val = val_dataset.map(preprocess_function, batched=True)\ntokenized_test = test_dataset.map(preprocess_function, batched=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-01T11:06:44.902649Z","iopub.execute_input":"2024-12-01T11:06:44.903339Z","iopub.status.idle":"2024-12-01T11:07:52.233332Z","shell.execute_reply.started":"2024-12-01T11:06:44.903304Z","shell.execute_reply":"2024-12-01T11:07:52.232577Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/20000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"89546b03126a4862b8b4caca51f80ecc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/5000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"50897409040c457498d0ee9ae2e871a3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/25000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c0fe455eed234706a8569f89ef745ed1"}},"metadata":{}}],"execution_count":11},{"cell_type":"markdown","source":"创建一个数据填充器，用于在训练时自动填充批次。并从指定的模型ID加载预训练模型","metadata":{}},{"cell_type":"code","source":"data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\nmodel = DebertaV2ForSequenceClassification.from_pretrained(\n    model_id,\n    # device_map=\"auto\",\n    # load_in_8bit=True\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-01T11:08:03.269146Z","iopub.execute_input":"2024-12-01T11:08:03.269500Z","iopub.status.idle":"2024-12-01T11:08:08.963640Z","shell.execute_reply.started":"2024-12-01T11:08:03.269468Z","shell.execute_reply":"2024-12-01T11:08:08.962911Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/874M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c30b09ce0c844c129627681f9774d12e"}},"metadata":{}},{"name":"stderr","text":"Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-large and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}],"execution_count":12},{"cell_type":"markdown","source":"定义LoRA配置，并使用peft库的函数准备模型，打印可训练参数。","metadata":{}},{"cell_type":"code","source":"# Define LoRA Config\nlora_config = LoraConfig(\n    r=16,\n    lora_alpha=32,\n    #target_modules=['q_proj', 'v_proj'],\n    lora_dropout=0.05,\n    bias=\"none\",\n    task_type=TaskType.SEQ_CLS\n)\n# prepare int-8 model for training\n# model = prepare_model_for_kbit_training(model)\n\n# add LoRA adaptor\nmodel = get_peft_model(model, lora_config)\nmodel.print_trainable_parameters()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-01T11:08:23.695631Z","iopub.execute_input":"2024-12-01T11:08:23.695992Z","iopub.status.idle":"2024-12-01T11:08:23.778724Z","shell.execute_reply.started":"2024-12-01T11:08:23.695960Z","shell.execute_reply":"2024-12-01T11:08:23.777925Z"}},"outputs":[{"name":"stdout","text":"trainable params: 1,574,914 || all params: 436,638,724 || trainable%: 0.3607\n","output_type":"stream"}],"execution_count":13},{"cell_type":"markdown","source":"加载准确率作为评估指标，并定义函数计算模型预测的准确率。","metadata":{}},{"cell_type":"code","source":"metric = evaluate.load(\"accuracy\")\ndef compute_metrics(eval_pred):\n    logits, labels = eval_pred\n    predictions = np.argmax(logits, axis=-1)\n    return metric.compute(predictions=predictions, references=labels)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-01T11:08:36.361021Z","iopub.execute_input":"2024-12-01T11:08:36.361754Z","iopub.status.idle":"2024-12-01T11:08:36.938516Z","shell.execute_reply.started":"2024-12-01T11:08:36.361717Z","shell.execute_reply":"2024-12-01T11:08:36.937736Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/4.20k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4f2e8484a18d4936b428c81c8c54a94a"}},"metadata":{}}],"execution_count":14},{"cell_type":"markdown","source":"定义了训练参数，包括输出目录、训练轮数、批次大小等。","metadata":{}},{"cell_type":"code","source":"training_args = TrainingArguments(\n    output_dir='./checkpoint',  # output directory\n    num_train_epochs=3,  # total number of training epochs\n    per_device_train_batch_size=2,  # batch size per device during training\n    per_device_eval_batch_size=4,  # batch size for evaluation\n    warmup_steps=500,  # number of warmup steps for learning rate scheduler\n    weight_decay=0.01,  # strength of weight decay\n    logging_dir='./logs',  # directory for storing logs\n    logging_steps=100,\n    save_strategy=\"no\",\n    evaluation_strategy=\"epoch\"\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-01T11:08:43.951121Z","iopub.execute_input":"2024-12-01T11:08:43.951471Z","iopub.status.idle":"2024-12-01T11:08:44.028658Z","shell.execute_reply.started":"2024-12-01T11:08:43.951439Z","shell.execute_reply":"2024-12-01T11:08:44.027778Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1545: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n  warnings.warn(\n","output_type":"stream"}],"execution_count":15},{"cell_type":"markdown","source":"创建一个训练器对象，传入模型、训练参数、数据集等。","metadata":{}},{"cell_type":"code","source":"trainer = Trainer(\n    model=model,  # the instantiated 🤗 Transformers model to be trained\n    args=training_args,  # training arguments, defined above\n    train_dataset=tokenized_train,  # training dataset\n    eval_dataset=tokenized_val,  # evaluation dataset\n    tokenizer=tokenizer,\n    data_collator=data_collator,\n    compute_metrics=compute_metrics,\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-01T11:08:46.508149Z","iopub.execute_input":"2024-12-01T11:08:46.508504Z","iopub.status.idle":"2024-12-01T11:08:47.830095Z","shell.execute_reply.started":"2024-12-01T11:08:46.508471Z","shell.execute_reply":"2024-12-01T11:08:47.829412Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"trainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-01T11:08:59.753885Z","iopub.execute_input":"2024-12-01T11:08:59.754565Z","iopub.status.idle":"2024-12-01T15:11:37.320254Z","shell.execute_reply.started":"2024-12-01T11:08:59.754532Z","shell.execute_reply":"2024-12-01T15:11:37.319509Z"}},"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  ········\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011113616922221405, max=1.0…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5d2cf44ec775453f94674714ec989a94"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.18.3"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20241201_110913-eevfp9uo</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/jiunianllin-/huggingface/runs/eevfp9uo' target=\"_blank\">./checkpoint</a></strong> to <a href='https://wandb.ai/jiunianllin-/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/jiunianllin-/huggingface' target=\"_blank\">https://wandb.ai/jiunianllin-/huggingface</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/jiunianllin-/huggingface/runs/eevfp9uo' target=\"_blank\">https://wandb.ai/jiunianllin-/huggingface/runs/eevfp9uo</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='30000' max='30000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [30000/30000 4:02:19, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.252800</td>\n      <td>0.167299</td>\n      <td>0.960400</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.110700</td>\n      <td>0.197795</td>\n      <td>0.962400</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.049200</td>\n      <td>0.191696</td>\n      <td>0.965000</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=30000, training_loss=0.18414618113438289, metrics={'train_runtime': 14556.6544, 'train_samples_per_second': 4.122, 'train_steps_per_second': 2.061, 'total_flos': 5.59869906096e+16, 'train_loss': 0.18414618113438289, 'epoch': 3.0})"},"metadata":{}}],"execution_count":17},{"cell_type":"markdown","source":"开始训练模型。","metadata":{}},{"cell_type":"code","source":"prediction_outputs = trainer.predict(tokenized_test)\ntest_pred = np.argmax(prediction_outputs[0], axis=-1).flatten()\nprint(test_pred)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-01T15:28:28.221919Z","iopub.execute_input":"2024-12-01T15:28:28.222260Z","iopub.status.idle":"2024-12-01T16:06:07.398729Z","shell.execute_reply.started":"2024-12-01T15:28:28.222233Z","shell.execute_reply":"2024-12-01T16:06:07.397935Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"[1 0 0 ... 0 1 1]\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"result_output = pd.DataFrame(data={\"id\": test[\"id\"], \"sentiment\": test_pred})\nresult_output.to_csv(\"deb0erta_lora_int8.csv\", index=False, quoting=3)\nlogging.info('result saved!')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-01T16:12:11.139834Z","iopub.execute_input":"2024-12-01T16:12:11.140644Z","iopub.status.idle":"2024-12-01T16:12:11.165973Z","shell.execute_reply.started":"2024-12-01T16:12:11.140609Z","shell.execute_reply":"2024-12-01T16:12:11.165297Z"}},"outputs":[],"execution_count":20}]}